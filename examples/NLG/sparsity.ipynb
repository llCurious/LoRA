{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path\n",
    "sys.path.append(\"/home/haoqi.whq/llm-inference/LoRA\")\n",
    "\n",
    "from src.model import GPT2Config, GPT2LMModel\n",
    "import torch\n",
    "from loralib import PruneLayer\n",
    "import loralib as lora\n",
    "import math\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "torch.Size([8, 512])\n",
      "torch.Size([8, 512])\n",
      "torch.Size([8, 512])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from src.data_utils import FT_Dataset\n",
    "\n",
    "train_data = \"./data/e2e/train.jsonl\"\n",
    "valid_data = \"./data/e2e/valid.jsonl\"\n",
    "train_batch_size = 8\n",
    "valid_batch_size = 4\n",
    "seq_len = 512\n",
    "obj = \"clm\"\n",
    "random_seed = 888\n",
    "label_smooth = 0.1\n",
    "\n",
    "train_data = FT_Dataset(\n",
    "    train_data, train_batch_size, seq_len, joint_lm=obj == \"jlm\"\n",
    ")\n",
    "\n",
    "valid_data = FT_Dataset(\n",
    "    valid_data,\n",
    "    valid_batch_size,\n",
    "    seq_len,\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=train_batch_size,\n",
    "    num_workers=0,\n",
    "    shuffle=False,\n",
    "    pin_memory=False,\n",
    "    drop_last=True,\n",
    "    # sampler=torch.utils.data.distributed.DistributedSampler(\n",
    "    #     train_data, seed=random_seed\n",
    "    # ),\n",
    ")\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "    valid_data,\n",
    "    batch_size=valid_batch_size,\n",
    "    num_workers=0,\n",
    "    shuffle=False,\n",
    "    pin_memory=False,\n",
    "    drop_last=False,\n",
    "    # sampler=torch.utils.data.distributed.DistributedSampler(\n",
    "    #     valid_data, seed=random_seed\n",
    "    # ),\n",
    ")\n",
    "\n",
    "print(type(train_loader))\n",
    "# data = train_loader[0]\n",
    "\n",
    "for i, data in enumerate(train_loader):\n",
    "    data = {key: value for key, value in data.items()}\n",
    "    _input = data[\"input\"]\n",
    "    _target = data[\"target\"]\n",
    "    _msk = data[\"mask\"]\n",
    "\n",
    "    print(_input.shape)\n",
    "    print(_target.shape)\n",
    "    print(_msk.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define and Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O Attention using LoRA: PruneGPTConv1D(\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "MLP using LoRA: PruneGPTConv1D(\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      "), PruneGPTConv1D(\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# medium GPT2\n",
    "config = GPT2Config(\n",
    "    n_embd=1024,\n",
    "    n_layer=24,\n",
    "    n_head=16,\n",
    "    lora_attn_dim=4,\n",
    "    lora_attn_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    "    enable_mlp=True,\n",
    "    enable_wo=True,\n",
    "    enable_wq=True,\n",
    "    enable_wk=True,\n",
    "    enable_wv=True,\n",
    ")\n",
    "\n",
    "lm_net = GPT2LMModel(config)\n",
    "\n",
    "# summary(lm_net, _input, lm_labels=_target, lm_mask=_msk, label_smooth=label_smooth, depth=6)\n",
    "# print(lm_net.state_dict())\n",
    "# transformer.h.0.attn.q_atten.lora_B\n",
    "# lm_head.decoder.weight\n",
    "# print(\"loading model pretrained weight.\")\n",
    "lm_net.load_lora_weight(\n",
    "    \"./pretrained_checkpoints/gpt2-medium-pytorch_model.bin\", \n",
    "    \"./tmp/retrain/qkvom/no_cp/model.ncp.lora.26000.pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PruneLinear(\n",
      "  in_features=1024, out_features=1024, bias=True\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(51542.3086, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.2918, requires_grad=True)\n",
      "PruneLinear(\n",
      "  in_features=1024, out_features=1024, bias=True\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(52160.0273, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.3672, requires_grad=True)\n",
      "PruneLinear(\n",
      "  in_features=1024, out_features=1024, bias=True\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(52289.1562, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.3830, requires_grad=True)\n",
      "PruneGPTConv1D(\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(54491.7422, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.6518, requires_grad=True)\n",
      "PruneGPTConv1D(\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(129962.5156, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.3458, requires_grad=True)\n",
      "PruneGPTConv1D(\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(128919.9688, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.2949, requires_grad=True)\n",
      "PruneLinear(\n",
      "  in_features=1024, out_features=1024, bias=True\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(51937.3789, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.3400, requires_grad=True)\n",
      "PruneLinear(\n",
      "  in_features=1024, out_features=1024, bias=True\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(51561.6758, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.2941, requires_grad=True)\n",
      "PruneLinear(\n",
      "  in_features=1024, out_features=1024, bias=True\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(51546.2773, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.2923, requires_grad=True)\n",
      "PruneGPTConv1D(\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(51536.6758, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.2911, requires_grad=True)\n",
      "PruneGPTConv1D(\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(128964.0312, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.2971, requires_grad=True)\n",
      "PruneGPTConv1D(\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(128773.5547, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.2878, requires_grad=True)\n",
      "PruneLinear(\n",
      "  in_features=1024, out_features=1024, bias=True\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(51511.4531, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.2880, requires_grad=True)\n",
      "PruneLinear(\n",
      "  in_features=1024, out_features=1024, bias=True\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(51539.0078, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.2914, requires_grad=True)\n",
      "PruneLinear(\n",
      "  in_features=1024, out_features=1024, bias=True\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(51491.9922, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.2856, requires_grad=True)\n",
      "PruneGPTConv1D(\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(51469.6562, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.2829, requires_grad=True)\n",
      "PruneGPTConv1D(\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(128862.1094, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.2921, requires_grad=True)\n",
      "PruneGPTConv1D(\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(128701.0156, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.2842, requires_grad=True)\n",
      "PruneLinear(\n",
      "  in_features=1024, out_features=1024, bias=True\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(51587.3008, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.2973, requires_grad=True)\n",
      "PruneLinear(\n",
      "  in_features=1024, out_features=1024, bias=True\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(51727.7852, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.3144, requires_grad=True)\n",
      "PruneLinear(\n",
      "  in_features=1024, out_features=1024, bias=True\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(51504.6172, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.2872, requires_grad=True)\n",
      "PruneGPTConv1D(\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(51504.3125, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.2871, requires_grad=True)\n",
      "PruneGPTConv1D(\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(129759.0312, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.3359, requires_grad=True)\n",
      "PruneGPTConv1D(\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(128614.5781, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.2800, requires_grad=True)\n",
      "PruneLinear(\n",
      "  in_features=1024, out_features=1024, bias=True\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(51615.7305, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.3007, requires_grad=True)\n",
      "PruneLinear(\n",
      "  in_features=1024, out_features=1024, bias=True\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(51627.7891, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.3022, requires_grad=True)\n",
      "PruneLinear(\n",
      "  in_features=1024, out_features=1024, bias=True\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(51559.9336, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.2939, requires_grad=True)\n",
      "PruneGPTConv1D(\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(51714.8633, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.3128, requires_grad=True)\n",
      "PruneGPTConv1D(\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(129770.0859, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.3364, requires_grad=True)\n",
      "PruneGPTConv1D(\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(128632.9844, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.2809, requires_grad=True)\n",
      "PruneLinear(\n",
      "  in_features=1024, out_features=1024, bias=True\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(51592.8008, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.2979, requires_grad=True)\n",
      "PruneLinear(\n",
      "  in_features=1024, out_features=1024, bias=True\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(51614.6797, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.3006, requires_grad=True)\n",
      "PruneLinear(\n",
      "  in_features=1024, out_features=1024, bias=True\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(51559.8672, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.2939, requires_grad=True)\n",
      "PruneGPTConv1D(\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(51553.3750, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.2931, requires_grad=True)\n",
      "PruneGPTConv1D(\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(129694.9297, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.3328, requires_grad=True)\n",
      "PruneGPTConv1D(\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(128615.8750, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.2801, requires_grad=True)\n",
      "PruneLinear(\n",
      "  in_features=1024, out_features=1024, bias=True\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(51706.9297, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.3119, requires_grad=True)\n",
      "PruneLinear(\n",
      "  in_features=1024, out_features=1024, bias=True\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(51714.4883, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.3128, requires_grad=True)\n",
      "PruneLinear(\n",
      "  in_features=1024, out_features=1024, bias=True\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(51575.8320, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.2959, requires_grad=True)\n",
      "PruneGPTConv1D(\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(51741.8477, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.3161, requires_grad=True)\n",
      "PruneGPTConv1D(\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(129614.7500, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.3288, requires_grad=True)\n",
      "PruneGPTConv1D(\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(128635.4609, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.2810, requires_grad=True)\n",
      "PruneLinear(\n",
      "  in_features=1024, out_features=1024, bias=True\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(51816.8047, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.3253, requires_grad=True)\n",
      "PruneLinear(\n",
      "  in_features=1024, out_features=1024, bias=True\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(51794.9414, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.3226, requires_grad=True)\n",
      "PruneLinear(\n",
      "  in_features=1024, out_features=1024, bias=True\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(51610.6719, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.3001, requires_grad=True)\n",
      "PruneGPTConv1D(\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(51852.2188, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.3296, requires_grad=True)\n",
      "PruneGPTConv1D(\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(129687.0469, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.3324, requires_grad=True)\n",
      "PruneGPTConv1D(\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(128643.2422, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.2814, requires_grad=True)\n",
      "PruneLinear(\n",
      "  in_features=1024, out_features=1024, bias=True\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(51706.1875, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.3118, requires_grad=True)\n",
      "PruneLinear(\n",
      "  in_features=1024, out_features=1024, bias=True\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(52112.0938, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.3613, requires_grad=True)\n",
      "PruneLinear(\n",
      "  in_features=1024, out_features=1024, bias=True\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(51576.5391, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.2960, requires_grad=True)\n",
      "PruneGPTConv1D(\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(51811.2891, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.3246, requires_grad=True)\n",
      "PruneGPTConv1D(\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(129524.0938, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.3244, requires_grad=True)\n",
      "PruneGPTConv1D(\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(128711.6016, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.2847, requires_grad=True)\n",
      "PruneLinear(\n",
      "  in_features=1024, out_features=1024, bias=True\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(51869.4375, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.3317, requires_grad=True)\n",
      "PruneLinear(\n",
      "  in_features=1024, out_features=1024, bias=True\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(52036.1953, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.3521, requires_grad=True)\n",
      "PruneLinear(\n",
      "  in_features=1024, out_features=1024, bias=True\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(51702.7305, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.3114, requires_grad=True)\n",
      "PruneGPTConv1D(\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(51881.1797, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.3332, requires_grad=True)\n",
      "PruneGPTConv1D(\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(129829.3359, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.3393, requires_grad=True)\n",
      "PruneGPTConv1D(\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(128704.4141, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.2844, requires_grad=True)\n",
      "PruneLinear(\n",
      "  in_features=1024, out_features=1024, bias=True\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(52109.7734, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.3611, requires_grad=True)\n",
      "PruneLinear(\n",
      "  in_features=1024, out_features=1024, bias=True\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(52129.1406, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.3634, requires_grad=True)\n",
      "PruneLinear(\n",
      "  in_features=1024, out_features=1024, bias=True\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(51627.4805, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.3022, requires_grad=True)\n",
      "PruneGPTConv1D(\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(52096.0703, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.3594, requires_grad=True)\n",
      "PruneGPTConv1D(\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(130408., grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.3676, requires_grad=True)\n",
      "PruneGPTConv1D(\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(128780.3438, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.2881, requires_grad=True)\n",
      "PruneLinear(\n",
      "  in_features=1024, out_features=1024, bias=True\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(52502.5508, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.4090, requires_grad=True)\n",
      "PruneLinear(\n",
      "  in_features=1024, out_features=1024, bias=True\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(53436.4062, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.5230, requires_grad=True)\n",
      "PruneLinear(\n",
      "  in_features=1024, out_features=1024, bias=True\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(51853.4766, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.3298, requires_grad=True)\n",
      "PruneGPTConv1D(\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(52250.6367, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.3783, requires_grad=True)\n",
      "PruneGPTConv1D(\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(130714.5156, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.3825, requires_grad=True)\n",
      "PruneGPTConv1D(\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(128697.7500, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.2841, requires_grad=True)\n",
      "PruneLinear(\n",
      "  in_features=1024, out_features=1024, bias=True\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(51929.3906, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.3390, requires_grad=True)\n",
      "PruneLinear(\n",
      "  in_features=1024, out_features=1024, bias=True\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(52456.9844, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.4034, requires_grad=True)\n",
      "PruneLinear(\n",
      "  in_features=1024, out_features=1024, bias=True\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(51625.2422, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.3019, requires_grad=True)\n",
      "PruneGPTConv1D(\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(51792.8555, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.3224, requires_grad=True)\n",
      "PruneGPTConv1D(\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(130892.4219, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.3912, requires_grad=True)\n",
      "PruneGPTConv1D(\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(128701.2031, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.2842, requires_grad=True)\n",
      "PruneLinear(\n",
      "  in_features=1024, out_features=1024, bias=True\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(53273.4805, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.5031, requires_grad=True)\n",
      "PruneLinear(\n",
      "  in_features=1024, out_features=1024, bias=True\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(52329.9453, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.3879, requires_grad=True)\n",
      "PruneLinear(\n",
      "  in_features=1024, out_features=1024, bias=True\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(51683.1602, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.3090, requires_grad=True)\n",
      "PruneGPTConv1D(\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(52349.8359, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.3904, requires_grad=True)\n",
      "PruneGPTConv1D(\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(130221.9844, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.3585, requires_grad=True)\n",
      "PruneGPTConv1D(\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(128682.7188, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.2833, requires_grad=True)\n",
      "PruneLinear(\n",
      "  in_features=1024, out_features=1024, bias=True\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(51848.4805, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.3292, requires_grad=True)\n",
      "PruneLinear(\n",
      "  in_features=1024, out_features=1024, bias=True\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(52066.2148, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.3557, requires_grad=True)\n",
      "PruneLinear(\n",
      "  in_features=1024, out_features=1024, bias=True\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(51584.1055, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.2969, requires_grad=True)\n",
      "PruneGPTConv1D(\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(51628.6055, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.3023, requires_grad=True)\n",
      "PruneGPTConv1D(\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(130226.3984, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.3587, requires_grad=True)\n",
      "PruneGPTConv1D(\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(128682.5703, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.2833, requires_grad=True)\n",
      "PruneLinear(\n",
      "  in_features=1024, out_features=1024, bias=True\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(52817.7812, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.4475, requires_grad=True)\n",
      "PruneLinear(\n",
      "  in_features=1024, out_features=1024, bias=True\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(53511.0352, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.5321, requires_grad=True)\n",
      "PruneLinear(\n",
      "  in_features=1024, out_features=1024, bias=True\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(51734.2383, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.3152, requires_grad=True)\n",
      "PruneGPTConv1D(\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(51982.9766, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.3456, requires_grad=True)\n",
      "PruneGPTConv1D(\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(130834.5938, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.3884, requires_grad=True)\n",
      "PruneGPTConv1D(\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(128730.9375, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.2857, requires_grad=True)\n",
      "PruneLinear(\n",
      "  in_features=1024, out_features=1024, bias=True\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(52279.2773, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.3817, requires_grad=True)\n",
      "PruneLinear(\n",
      "  in_features=1024, out_features=1024, bias=True\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(52528.0352, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.4121, requires_grad=True)\n",
      "PruneLinear(\n",
      "  in_features=1024, out_features=1024, bias=True\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(51856.9883, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.3302, requires_grad=True)\n",
      "PruneGPTConv1D(\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(53530.5703, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.5345, requires_grad=True)\n",
      "PruneGPTConv1D(\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(130770.6562, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.3853, requires_grad=True)\n",
      "PruneGPTConv1D(\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(128742.6719, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.2863, requires_grad=True)\n",
      "PruneLinear(\n",
      "  in_features=1024, out_features=1024, bias=True\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(53072.6758, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.4786, requires_grad=True)\n",
      "PruneLinear(\n",
      "  in_features=1024, out_features=1024, bias=True\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(52638.5898, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.4256, requires_grad=True)\n",
      "PruneLinear(\n",
      "  in_features=1024, out_features=1024, bias=True\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(51652.1055, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.3052, requires_grad=True)\n",
      "PruneGPTConv1D(\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(52201.1914, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.3722, requires_grad=True)\n",
      "PruneGPTConv1D(\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(131896.5938, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.4403, requires_grad=True)\n",
      "PruneGPTConv1D(\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(128822.2969, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.2902, requires_grad=True)\n",
      "PruneLinear(\n",
      "  in_features=1024, out_features=1024, bias=True\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(52432.8984, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.4005, requires_grad=True)\n",
      "PruneLinear(\n",
      "  in_features=1024, out_features=1024, bias=True\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(53095.4414, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.4814, requires_grad=True)\n",
      "PruneLinear(\n",
      "  in_features=1024, out_features=1024, bias=True\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(52094.7070, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.3592, requires_grad=True)\n",
      "PruneGPTConv1D(\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(52494.3750, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.4080, requires_grad=True)\n",
      "PruneGPTConv1D(\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(131932.5000, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.4420, requires_grad=True)\n",
      "PruneGPTConv1D(\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(128818.5938, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.2900, requires_grad=True)\n",
      "PruneLinear(\n",
      "  in_features=1024, out_features=1024, bias=True\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(52287.1797, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.3827, requires_grad=True)\n",
      "PruneLinear(\n",
      "  in_features=1024, out_features=1024, bias=True\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(52837.3164, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.4499, requires_grad=True)\n",
      "PruneLinear(\n",
      "  in_features=1024, out_features=1024, bias=True\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(52920.1484, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.4600, requires_grad=True)\n",
      "PruneGPTConv1D(\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(53498.5703, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.5306, requires_grad=True)\n",
      "PruneGPTConv1D(\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(132592.3281, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.4742, requires_grad=True)\n",
      "PruneGPTConv1D(\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(128914.4219, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.2946, requires_grad=True)\n",
      "PruneLinear(\n",
      "  in_features=1024, out_features=1024, bias=True\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(52294.4805, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.3836, requires_grad=True)\n",
      "PruneLinear(\n",
      "  in_features=1024, out_features=1024, bias=True\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(52905.8594, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.4582, requires_grad=True)\n",
      "PruneLinear(\n",
      "  in_features=1024, out_features=1024, bias=True\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(54298.9961, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.6283, requires_grad=True)\n",
      "PruneGPTConv1D(\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(54075.5547, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.6010, requires_grad=True)\n",
      "PruneGPTConv1D(\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(132774.8125, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.4831, requires_grad=True)\n",
      "PruneGPTConv1D(\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(128959.5000, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.2969, requires_grad=True)\n",
      "PruneLinear(\n",
      "  in_features=1024, out_features=1024, bias=True\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(52338.5469, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.3890, requires_grad=True)\n",
      "PruneLinear(\n",
      "  in_features=1024, out_features=1024, bias=True\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(52901.2891, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.4577, requires_grad=True)\n",
      "PruneLinear(\n",
      "  in_features=1024, out_features=1024, bias=True\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(52985.0977, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.4679, requires_grad=True)\n",
      "PruneGPTConv1D(\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(55576.0078, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.7842, requires_grad=True)\n",
      "PruneGPTConv1D(\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(133483.2812, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.5177, requires_grad=True)\n",
      "PruneGPTConv1D(\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(129255.9766, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.3113, requires_grad=True)\n",
      "PruneLinear(\n",
      "  in_features=1024, out_features=1024, bias=True\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(52184.7305, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.3702, requires_grad=True)\n",
      "PruneLinear(\n",
      "  in_features=1024, out_features=1024, bias=True\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(52765.6797, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.4411, requires_grad=True)\n",
      "PruneLinear(\n",
      "  in_features=1024, out_features=1024, bias=True\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(53524.3086, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.5337, requires_grad=True)\n",
      "PruneGPTConv1D(\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(52255.2734, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.3788, requires_grad=True)\n",
      "PruneGPTConv1D(\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(134536.5000, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.5692, requires_grad=True)\n",
      "PruneGPTConv1D(\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(130202.2266, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.3575, requires_grad=True)\n",
      "PruneLinear(\n",
      "  in_features=1024, out_features=1024, bias=True\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(52354.3672, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.3909, requires_grad=True)\n",
      "PruneLinear(\n",
      "  in_features=1024, out_features=1024, bias=True\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(52483.5820, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.4067, requires_grad=True)\n",
      "PruneLinear(\n",
      "  in_features=1024, out_features=1024, bias=True\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(53648.6797, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.5489, requires_grad=True)\n",
      "PruneGPTConv1D(\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(52216.5352, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.3741, requires_grad=True)\n",
      "PruneGPTConv1D(\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(142304.5938, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.9485, requires_grad=True)\n",
      "PruneGPTConv1D(\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ") tensor(132328.5781, grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(6.4614, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for m in lm_net.modules():\n",
    "    if isinstance(m, PruneLayer):\n",
    "        print(m, m.complexity(), m.lora_scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_net.cuda()\n",
    "lm_net = torch.nn.DataParallel(lm_net)\n",
    "\n",
    "lora.mark_only_lora_as_trainable(lm_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\n",
    "    Imported from https://github.com/pytorch/examples/blob/master/imagenet/main.py#L247-L262\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Prune LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora.prune_lora(lm_net, percent_prune=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haoqi.whq/miniconda3/envs/llm-qd/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/haoqi.whq/miniconda3/envs/llm-qd/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval samples: 0 loss: tensor(1.8663, device='cuda:0')\n",
      "eval samples: 100 loss: tensor(1.6873, device='cuda:0')\n",
      "eval samples: 200 loss: tensor(2.0302, device='cuda:0')\n",
      "eval samples: 300 loss: tensor(2.0830, device='cuda:0')\n",
      "eval samples: 400 loss: tensor(2.3319, device='cuda:0')\n",
      "eval samples: 500 loss: tensor(2.3907, device='cuda:0')\n",
      "eval samples: 600 loss: tensor(2.0874, device='cuda:0')\n",
      "eval samples: 700 loss: tensor(1.7890, device='cuda:0')\n",
      "eval samples: 800 loss: tensor(2.1447, device='cuda:0')\n",
      "eval samples: 900 loss: tensor(2.5808, device='cuda:0')\n",
      "eval samples: 1000 loss: tensor(2.3787, device='cuda:0')\n",
      "eval samples: 1100 loss: tensor(1.9162, device='cuda:0')\n",
      "2.0083035004057295 7.450666566523994\n"
     ]
    }
   ],
   "source": [
    "lm_net.eval()\n",
    "avg_lm_loss = AverageMeter()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for idx, data in enumerate(valid_loader):\n",
    "        data = {key: value for key, value in data.items()}\n",
    "\n",
    "        _input = data[\"input\"].cuda()\n",
    "        _target = data[\"target\"].cuda()\n",
    "        _msk = data[\"mask\"].cuda()\n",
    "\n",
    "        _lm_logits, _loss = lm_net(_input, lm_labels=_target, lm_mask=_msk)\n",
    "        loss = _loss.mean()\n",
    "\n",
    "        avg_lm_loss.update(loss.item())\n",
    "\n",
    "        if idx % 100 == 0:\n",
    "            print(\"eval samples:\", idx, \"loss:\", loss.float())\n",
    "\n",
    "print(avg_lm_loss.avg, math.exp(avg_lm_loss.avg))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-qd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
